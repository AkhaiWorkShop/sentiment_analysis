{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49198d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import emoji\n",
    "import re\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedcacc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Dataset Loaded ===\n",
      "(1815, 2)\n",
      "  sentimen                                              tweet\n",
      "0  negatif  Kata @prabowo Indonesia tidak dihargai bangsa ...\n",
      "1   netral  Batuan Langka, Tasbih Jokowi Hadiah dari Habib...\n",
      "✅ Loaded slang dictionary (1089 entries dipakai dari 15167 total)\n",
      "\n",
      "=== Mulai preprocessing (negation-aware)... ===\n",
      "✅ Preprocessing selesai!\n",
      "✅ Data bersih disimpan ke: ../data/dataset_clean.csv\n",
      "\n",
      "=== Contoh Sebelum & Sesudah ===\n",
      "\n",
      "[1] Tweet Asli: Kata @prabowo Indonesia tidak dihargai bangsa asing!   Berita ini ðŸ‘‡ pasti hoax buatan penguasa, ya kan @rockygerung?ðŸ˜œ https://twitter.com/mediaindonesia/status/1117575436337160192?s=21Â â€¦\n",
      "[1] Setelah Bersih: kata indonesia dihargai bangsa asing berita ðÿ hoaks buatan penguasa kan ðÿ œ â\n",
      "\n",
      "[2] Tweet Asli: Batuan Langka, Tasbih Jokowi Hadiah dari Habib Luthfi Seharga Mercy?  http://dlvr.it/R2pvZVÂ \n",
      "[2] Setelah Bersih: batuan langka tasbih jokowi hadiah habib luthfi seharga mercy\n",
      "\n",
      "[3] Tweet Asli: Di era Jokowi, ekonomi Indonesia semakin baik. #01IndonesiaMaju #JokowiLagi #JokowiMenangTotalDebat pic.twitter.com/W2ythnxsTp\n",
      "[3] Setelah Bersih: era jokowi ekonomi indonesia semakin baik 01indonesiamaju jokowilagi jokowimenangtotaldebat pic twitter com w2ythnxstp\n"
     ]
    }
   ],
   "source": [
    "# ========== 1️⃣ LOAD DATA ==========\n",
    "df = pd.read_csv(\"../data/dataset.csv\")\n",
    "df = df.drop(columns=['Unnamed: 0'], errors='ignore')\n",
    "\n",
    "print(\"=== Dataset Loaded ===\")\n",
    "print(df.shape)\n",
    "print(df.head(2))\n",
    "\n",
    "# ========== 2️⃣ LOAD SLANG DICTIONARY ==========\n",
    "try:\n",
    "    slang_df = pd.read_csv(\n",
    "        \"../data/indo_slang_new.csv\",\n",
    "        encoding=\"latin1\",\n",
    "        names=[\"slang\", \"formal\"]\n",
    "    )\n",
    "    slang_df = slang_df.dropna().drop_duplicates()\n",
    "    slang_dict = dict(zip(slang_df[\"slang\"].astype(str).str.lower(), slang_df[\"formal\"].astype(str).str.lower()))\n",
    "\n",
    "    # Filter hanya slang yang muncul di dataset\n",
    "    text_all = \" \".join(df[\"tweet\"].astype(str)).lower()\n",
    "    text_tokens = set(text_all.split())\n",
    "    slang_dict = {k: v for k, v in slang_dict.items() if k in text_tokens}\n",
    "    print(f\"✅ Loaded slang dictionary ({len(slang_dict)} entries dipakai dari {len(slang_df)} total)\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Gagal load slang.csv, fallback ke default. Error: {e}\")\n",
    "    slang_dict = {\n",
    "        \"gk\": \"gak\", \"ga\": \"gak\", \"bgt\": \"banget\", \"tdk\": \"tidak\", \n",
    "        \"yg\": \"yang\", \"dgn\": \"dengan\", \"utk\": \"untuk\", \"nggak\": \"tidak\",\n",
    "        \"wowo\": \"prabowo\", \"bowo\": \"prabowo\", \"jae\": \"jokowi\", \"pakde\": \"jokowi\",\n",
    "        \"jkw\": \"jokowi\", \"uno\": \"sandiaga\", \"bang sandi\": \"sandiaga\", \"sandi\": \"sandiaga\"\n",
    "    }\n",
    "\n",
    "# Jangan normalisasi kata negasi\n",
    "negation_words = {\"tidak\", \"bukan\", \"jangan\", \"belum\", \"tanpa\", \"kurang\"}\n",
    "slang_dict = {k: v for k, v in slang_dict.items() if k not in negation_words}\n",
    "\n",
    "# ========== 3️⃣ CUSTOM STOPWORD REMOVER (NEGATION-AWARE) ==========\n",
    "factory = StopWordRemoverFactory()\n",
    "default_stopwords = set(factory.get_stop_words())\n",
    "important_words = {\"bukan\", \"tidak\", \"jangan\", \"belum\", \"tanpa\", \"kurang\"}\n",
    "custom_stopwords = list(default_stopwords - important_words)\n",
    "stopword_remover = factory.create_stop_word_remover()\n",
    "stopword_remover.stop_words = custom_stopwords\n",
    "\n",
    "# ========== 4️⃣ PRECOMPILE SLANG REGEX ==========\n",
    "if slang_dict:\n",
    "    slang_pattern = re.compile(r'\\b(' + '|'.join(re.escape(k) for k in slang_dict.keys()) + r')\\b')\n",
    "else:\n",
    "    slang_pattern = None\n",
    "\n",
    "# ========== 5️⃣ EMOJI MAPPING ==========\n",
    "EMOJI_MAPPING = {\n",
    "    \":face_with_tears_of_joy:\": \"tertawa\",\n",
    "    \":loudly_crying_face:\": \"sedih\",\n",
    "    \":smiling_face_with_heart_eyes:\": \"cinta\",\n",
    "    \":folded_hands:\": \"berdoa\",\n",
    "    \":angry_face:\": \"marah\",\n",
    "    \":thumbs_up:\": \"setuju\",\n",
    "    \":thinking_face:\": \"berpikir\",\n",
    "    \":clapping_hands:\": \"dukung\",\n",
    "    \":red_heart:\": \"cinta\",\n",
    "    \":broken_heart:\": \"kecewa\",\n",
    "    \":fire:\": \"semangat\",\n",
    "    \":skull:\": \"gagal\",\n",
    "    \":money_bag:\": \"uang\",\n",
    "    \":flag_for_Indonesia:\": \"indonesia\",\n",
    "    \":prayer_beads:\": \"tasbih\",\n",
    "}\n",
    "\n",
    "def demojize_to_text(text: str) -> str:\n",
    "    text = emoji.demojize(text, delimiters=(\" \", \" \"))\n",
    "    for code, word in EMOJI_MAPPING.items():\n",
    "        text = text.replace(code, f\"[{word}]\")\n",
    "    return text\n",
    "\n",
    "# ========== 6️⃣ PREPROCESS FUNCTION (OPTIMIZED) ==========\n",
    "def preprocess(text: str) -> str:\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return \"\"\n",
    "\n",
    "    # 1. Lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # 2. Hapus URL\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text)\n",
    "\n",
    "    # 3. Hapus mention @user, tapi ubah #hashtag jadi teks\n",
    "    text = re.sub(r\"@\\w+\", \"\", text)\n",
    "    text = re.sub(r\"#(\\w+)\", r\"\\1\", text)\n",
    "\n",
    "    # 4. Konversi emoji ke kata\n",
    "    text = demojize_to_text(text)\n",
    "\n",
    "    # 5. Normalisasi duplikasi karakter (opsional tapi disarankan)\n",
    "    text = re.sub(r'(.)\\1{2,}', r'\\1\\1', text)\n",
    "\n",
    "    # 6. Normalisasi slang\n",
    "    if slang_pattern:\n",
    "        text = slang_pattern.sub(lambda x: slang_dict.get(x.group(), x.group()), text)\n",
    "\n",
    "    # 7. Hapus tanda baca & simbol non-huruf/angka/spasi\n",
    "    text = re.sub(r\"[^\\w\\s]\", \" \", text)\n",
    "\n",
    "    # 8. Bersihkan spasi berlebih\n",
    "    text = \" \".join(text.split())\n",
    "\n",
    "    # 9. Stopword removal (tanpa buang kata negasi)\n",
    "    text = stopword_remover.remove(text)\n",
    "\n",
    "    10. (Opsional) Stemming — aktifkan jika ingin\n",
    "    from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "    stemmer = StemmerFactory().create_stemmer()\n",
    "    text = stemmer.stem(text)\n",
    "\n",
    "    return text.strip()\n",
    "\n",
    "# ========== 7️⃣ JALANKAN PIPELINE ==========\n",
    "print(\"\\n=== Mulai preprocessing (negation-aware)... ===\")\n",
    "df[\"clean_tweet\"] = df[\"tweet\"].astype(str).apply(preprocess)\n",
    "print(\"✅ Preprocessing selesai!\")\n",
    "\n",
    "# ========== 8️⃣ SIMPAN HASIL ==========\n",
    "output_path = \"../data/dataset_clean.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"✅ Data bersih disimpan ke: {output_path}\")\n",
    "\n",
    "# ========== 9️⃣ CONTOH HASIL ==========\n",
    "print(\"\\n=== Contoh Sebelum & Sesudah ===\")\n",
    "for i in range(min(3, len(df))):\n",
    "    print(f\"\\n[{i+1}] Tweet Asli: {df['tweet'].iloc[i]}\")\n",
    "    print(f\"[{i+1}] Setelah Bersih: {df['clean_tweet'].iloc[i]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
